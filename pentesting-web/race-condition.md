# Race Condition

## Anything limited by a number of attempts

Race conditions are **vulnerabilities** that **appear** in webs that **limit the number of times you can perform an action**. A very easy example can be found in [**this report**](https://medium.com/@pravinponnusamy/race-condition-vulnerability-found-in-bug-bounty-program-573260454c43).

## Using several times a one-time use code

When you make the web page perform some **action** that **should be done only once**, but if the action is done **several times** you will be **benefited**, you really need to try a **Race condicion**.\
Most of the time this is directly related with **money** (if an action is made you get X money, so let's try to make it several time very quickly)**.**

### **Using from the same account the same code several times**

For example, in [**this bug** ](https://hackerone.com/reports/759247)the hunter was able to **load the money inside a gift card several times.**

This is the **turbo intruder** script used to **test** the **race condition** of the mentioned writeup:

```python
def queueRequests(target, wordlists):
    engine = RequestEngine(endpoint=target.endpoint,
                           concurrentConnections=30,
                           requestsPerConnection=30,
                           pipeline=False
                           )

   for i in range(30):
    engine.queue(target.req, i)
        engine.queue(target.req, target.baseInput, gate='race1')


    engine.start(timeout=5)
   engine.openGate('race1')

    engine.complete(timeout=60)


def handleResponse(req, interesting):
    table.add(req)
```

Using also BURP you could also send the **request** to **Intruder**, set the **number of threads** to **30** inside the **Options menu and,** select as payload **Null payloads** and generate **30.**

### **Using the same code from different accounts**

**If the previously proposal didn't work (try to use the same code several times from the same account) you try a variant:Try t use the same code from different accounts:**

```python
def queueRequests(target, wordlists):
    engine = RequestEngine(endpoint=target.endpoint,
                           concurrentConnections=5,
                           requestsPerConnection=1,
                           pipeline=False
                           )
    a = ['Session=<session_id_1>','Session=<session_id_2>','Session=<session_id_3>']
    for i in range(len(a)):
        engine.queue(target.req,a[i], gate='race1')
    # open TCP connections and send partial requests
    engine.start(timeout=10)
    engine.openGate('race1')
    engine.complete(timeout=60)

def handleResponse(req, interesting):
    table.add(req)
```

### OAuth2 eternal persistence

There are several [**OAUth providers**](https://en.wikipedia.org/wiki/List\_of\_OAuth\_providers). Theses services will allow you to create an application and authenticate users that the provider has registered. In order to do so, the **client** will need to **permit your application** to access some of their data inside of the **OAUth provider**.\
So, until here just a common login with google/linkdin/github... where you aer prompted with a page saying: "_Application \<InsertCoolName> wants to access you information, do you want to allow it?_"

#### Race Condition in `authorization_code`

The **problem** appears when you **accept it** and automatically sends a **`authorization_code`** to the malicious application. Then, this **application abuses a Race Condition in the OAUth service provider to generate more that one AT/RT** (_Authentication Token/Refresh Token_) from the **`authorization_code`** for your account. Basically, it will abuse the fact that you have accept the application to access your data to **create several accounts**. Then, if you **stop allowing the application to access your data one pair of AT/RT will be deleted, but the other ones will still be valid**.

#### Race Condition in `Refresh Token`

Once you have **obtained a valid RT** you could try to **abuse it to generate several AT/RT** and **even if the user cancels the permissions** for the malicious application to access his data, **several RTs will still be valid.**

John wants to transfer 100 dollars that he has in his account to Peter. He goes to the Transfers tab, enters Peter’s nickname, and “100” into the field with the amount of funds to be transferred. Next, he clicks on the Transfer button. The data is sent to the web application.

What is happening inside? What does the programmer need to do for everything to work correctly?

1\. Make sure that John has enough money in his account

The system needs to make sure that John has sufficient funds to transfer the required amount. It is necessary to get the value of his current balance; if it is less than the amount that he wants to transfer, notify him about it. We must bear in mind that our web service does not provide loans and the balance cannot go negative.

2\. Subtract the amount to be transferred from the user’s balance

We should update the balance of the current user deducting the amount transferred. It was 100, it became 100-100 = 0.

3\. Add to Peter’s balance the amount that was transferred

At the Peter’s side, it is the opposite: it was 0, it became 0+100 = 100.

4\. Display a message to the user that everything is fine!

When writing programs, a person takes the simplest algorithms and then combines them into a single plot which will make the script of a new program. In our case, the programmer’s task is to write the logic of money transfers (points, credits) from one person to another in a web application.

Guided by logic, we can compose an algorithm consisting of several checks. Imagine that we just removed everything unnecessary and compiled a pseudocode.

**Pseudocode**

```
If (John.Balance >= transfer_amount) Then
   John.Balance = John.Balance - transfer_amount
   Peter.Balance = Peter.Balance + transfer_amount
   Congratulations ()
Else
   Error ()
```

And there would be no problems if everything happened in an orderly fashion. However, the site can serve many users at the same time, and this does not happen in one thread, because modern web applications use multiprocessing and multithreading to process data in parallel. With the introduction of multithreading, programs inherited a funny architectural vulnerability: the race condition.

Now imagine that our algorithm is triggered simultaneously 3 times.

John still has 100 points on his balance, but somehow he managed to make three requests to the web application in three threads at the same time (with a minimum amount of time between requests). All three threads check whether the user ‘Peter’ exists or not, and check if John has sufficient funds to transfer the required amount. At the moment when the algorithm checks the balance, it is still 100. As soon as the verification is completed, 100 is deducted 3 times from the current balance and added to the Peter’s account.

What is the result? John has a negative balance in his account (100-300 = -200 points). Meanwhile, Peter has 300 points, although it should be 100. This is a typical example of the race condition exploitation. It is akin to a situation when several people slip in using one ID card. Below is the screenshot of such a case from [@4lemon](https://twitter.com/4lemon)

![race condition](https://bo0om.ru/wp-content/uploads/2019/07/race-condition.png)

The race condition occurs both in multithreaded applications and in the databases in which they work. And it is not limited to web applications only. For example, this is a common criterion for privilege escalation in operating systems.  Nevertheless, web applications have their own characteristics for successful exploitation, which I want to talk about.

###

### **Typical Race Condition Exploitation** <a href="#h-typical-race-condition-exploitation" id="h-typical-race-condition-exploitation"></a>

> ”A hacker walks into a hookah lounge, an escape room, and a bar. The bartender says to him, “You have a race condition!”
>
> Omar Ganiev

In most cases, multithreaded software is used as a client to check/exploit the race condition, e.g. Burp Suite and its Intruder tool. They put one HTTP request on repeat, create multiple threads, and start flooding. Like, for example, in this [article](https://medium.com/@valeriyshevchenko/how-to-check-race-conditions-in-web-applications-338f73937992). Or in this [one](https://medium.com/@ciph3r7r0ll/race-condition-bug-in-web-app-a-use-case-21fd4df71f0e). This is a fairly working way if the server allows the use of multiple threads to its resource, and as the articles above say: if it didn’t work, try again. But the fact is that in some cases this may not be effective. Especially if we think back to how such applications access the server.

**What’s on the server side**

Each thread establishes a TCP connection, sends data, waits for a response, closes the connection, opens it again, sends data, and so on. At first glance, all data is sent at the same time, but HTTP requests themselves may not arrive synchronously due to the nature of the transport layer, the need to establish a secure connection (HTTPS) and resolve DNS (not in the case of Burp), as well as due to many layers of abstraction that data pass through before being sent to a network device. When it comes to milliseconds, this can play a key role.

###

### **HTTP Pipelining** <a href="#h-http-pipelining" id="h-http-pipelining"></a>

One can recall HTTP Pipelining, where client sends data using a single socket. You can check for yourself how it works with the netcat utility (you’ve got GNU/Linux, right?).

_In fact, you better use Linux for many reasons: there is a more modern TCP/IP stack, which is supported by the operating system kernels. The server is most likely on Linux, as well._

For example, run nc google.com 80 command and insert the following lines there

> ```
> GET / HTTP/1.1
> Host: google.com
>
> GET / HTTP/1.1
> Host: google.com
>
> GET / HTTP/1.1
> Host: google.com
> ```

Thus, within one connection, three HTTP requests will be sent, and you will receive three HTTP responses. This feature can be used to minimize the time between requests.

**What’s on the server side**

The web server receives requests sequentially (this is the key point), and processes the responses in the same order. This peculiarity can be used to attack in several steps (when it is necessary to sequentially perform two actions in the minimum amount of time) or, for example, to slow down the server in the first request in order to increase the success of the attack.\
Trick: You can prevent the server from processing your request by loading its DBMS, especially if INSERT/UPDATE is used. Heavier requests can “slow down” your load, thus, it will be more likely that you will win this race.

###

### **Splitting an HTTP Request Into Two Parts** <a href="#h-splitting-an-http-request-into-two-parts" id="h-splitting-an-http-request-into-two-parts"></a>

First, let’s brush up on how the HTTP request is generated.\
Well, as you know, the first line is the method, path, and the protocol version:

```
GET / HTTP/1.1
```

Next are the headers before the line break:

```
Host: google.com
Cookie: a=1
```

But how does the web server know that the HTTP request has ended?

Let’s look at an example. Enter nc google.com 80, and there

```
GET / HTTP/1.1
Host: google.com
```

After you press ENTER, nothing will happen. Click again, and you will see the response.

That is, for the web server to accept the HTTP request, two line breaks are necessary. And the valid request looks like this:

```
GET / HTTP/1.1\r\nHost: google.com\r\n
```

If this were the POST method (don’t forget about Content-Length), then the correct HTTP request would be like this:

```
POST / HTTP/1.1
Host: google.com
Content-Length: 3

a=1
```

&#x20;

Try sending a similar request from the command line:

```
echo -ne "GET / HTTP/1.1\r\nHost: google.com\r\n\r\n" | nc google.com 80
```

&#x20;

As a result, you will indeed get a response, since our HTTP request is complete. It won’t be the case, though, if you remove the last \n character.

_In fact, many web servers just need to use \n as the line feed character, so it’s important not to swap \r and \n, otherwise further tricks may not work._

So, where does that leave us?  You can simultaneously open many connections to a resource, send 99% of your HTTP request, and leave the last byte unsent. The server will wait until you send the last character, the line feed. Once it’s clear that the main part of the data has been sent, send the last byte (or several bytes).\
This is especially important when it comes to a large POST request, for example, when a file upload is necessary. However, this makes sense even with small requests, since delivering a few bytes is much faster than simultaneously sending kilobytes of data.

###

### Delay Before Sending the Second Part of the Request <a href="#h-delay-before-sending-the-second-part-of-the-request" id="h-delay-before-sending-the-second-part-of-the-request"></a>

According to the research of [Vlad Roskov](https://twitter.com/leetmore), you should not only split the request, but also make a delay of several seconds between sending the main part of the data and the final one. And all because web servers begin to parse requests even before they receive it completely.

![](https://bo0om.ru/wp-content/uploads/2019/07/RaceDelay.png)

**What’s on the server side**

For example, when receiving HTTP request headers, nginx starts parsing them caching the incomplete request. When the last byte arrives, the web server will take the partially processed request and send it directly to the application, thereby reducing the processing time of requests, which increases the likelihood of an attack.

###

### How to Deal With It <a href="#h-how-to-deal-with-it" id="h-how-to-deal-with-it"></a>

First of all, this is an architectural problem. If you properly design a web application, you can avoid such races.

Typically, the following attack prevention techniques are used:

* [Locks](https://en.wikipedia.org/wiki/Record\_locking).\
  The operation blocks the access to the locked object in the DBMS until it is unlocked. Others stand and wait on the sidelines. It is necessary to work with locks correctly, not to lock anything extra.
* [Isolations](https://en.wikipedia.org/wiki/Isolation\_\(database\_systems\)).\
  Serializable transactions ensure strictly sequential execution. This, however, can impact performance.
* [Mutual exclusions](https://en.wikipedia.org/wiki/Mutual\_exclusion).\
  We use a tool like etcd to create an entry with a key at each function call. If it is not possible to create an entry, then it already exists and the request is interrupted. At the end of request processing, the entry is deleted.

I actually enjoyed the [video by Ivan Rabotyaga](https://www.youtube.com/watch?v=AYWiRVdJFTI) about locks and transactions, it is very informative.

## References

* [https://hackerone.com/reports/759247](https://hackerone.com/reports/759247)
* [https://pandaonair.com/2020/06/11/race-conditions-exploring-the-possibilities.html](https://pandaonair.com/2020/06/11/race-conditions-exploring-the-possibilities.html)
* [https://hackerone.com/reports/55140](https://hackerone.com/reports/55140)
